{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Chapter 7 Code\n\nCovers code for Chapter 7, \"Reframing Difficult Deep Learning Problems\", of *Modern Deep Learning Design and Application*.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"# array processing + math\nimport numpy as np\nimport pandas as pd\nimport math\n\n# plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# looping\nfrom tqdm.notebook import tqdm\n\n# deep learning staple libraries\nimport sklearn\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# keras specifics\nimport keras.layers as L\nimport keras.backend as K\nfrom keras.utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:20:05.137508Z","iopub.execute_input":"2021-08-26T17:20:05.137894Z","iopub.status.idle":"2021-08-26T17:20:05.143195Z","shell.execute_reply.started":"2021-08-26T17:20:05.137853Z","shell.execute_reply":"2021-08-26T17:20:05.142278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## DeepInsight","metadata":{}},{"cell_type":"markdown","source":"### Install + Import pyDeepInsight","metadata":{}},{"cell_type":"code","source":"!pip install git+git://github.com/alok-ai-lab/DeepInsight.git#egg=DeepInsight","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:20:05.980285Z","iopub.execute_input":"2021-08-26T17:20:05.980641Z","iopub.status.idle":"2021-08-26T17:20:05.984739Z","shell.execute_reply.started":"2021-08-26T17:20:05.980604Z","shell.execute_reply":"2021-08-26T17:20:05.983634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data.drop('class',axis=1),\n                                                    data['class'],\n                                                    train_size=0.8)\ny_train = keras.utils.to_categorical(y_train)\ny_test = keras.utils.to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:20:06.238701Z","iopub.execute_input":"2021-08-26T17:20:06.238984Z","iopub.status.idle":"2021-08-26T17:20:06.242657Z","shell.execute_reply.started":"2021-08-26T17:20:06.238958Z","shell.execute_reply":"2021-08-26T17:20:06.241484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyDeepInsight import ImageTransformer, LogScaler\nln = LogScaler()\nX_train_norm = ln.fit_transform(X_train)\nX_test_norm = ln.transform(X_test)\nit = ImageTransformer(feature_extractor='kpca', \n                      pixels=32)\ntf_train_x = it.fit_transform(X_train_norm)\ntf_test_x = it.transform(X_test_norm)\n\nfor i in range(5):\n    plt.figure(figsize=(10,10))\n    plt.imshow(tf_train_x[i])\n    plt.axis('off')\n    plt.savefig(f'{i}.png', dpi=400)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:20:06.470147Z","iopub.execute_input":"2021-08-26T17:20:06.470457Z","iopub.status.idle":"2021-08-26T17:20:06.474614Z","shell.execute_reply.started":"2021-08-26T17:20:06.470427Z","shell.execute_reply":"2021-08-26T17:20:06.473127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input\ninp = L.Input((32,32,3))\n\n# branch 1\nx = inp\nfor i in range(3):\n    x = L.Conv2D(2**(i+3), (2,1), padding='same')(x)\n    x = L.Conv2D(2**(i+3), (1,2), padding='same')(x)\n    x = L.Conv2D(2**(i+3), (2,2), padding='same')(x)\n    x = L.BatchNormalization()(x)\n    x = L.Activation('relu')(x)\n    x = L.MaxPooling2D((2,2))(x)\n    x = L.Dropout(0.3)(x)\nx = L.Conv2D(64, (2,2), padding='same')(x)\nx = L.BatchNormalization()(x)\nbranch_1 = L.Activation('relu')(x)\n\n# branch 2\nx = inp\nfor i in range(3):\n    x = L.Conv2D(2**(i+3), (5,1), padding='same')(x)\n    x = L.Conv2D(2**(i+3), (1,5), padding='same')(x)\n    x = L.Conv2D(2**(i+3), (5,5), padding='same')(x)\n    x = L.BatchNormalization()(x)\n    x = L.Activation('relu')(x)\n    x = L.MaxPooling2D((2,2))(x)\n    x = L.Dropout(0.3)(x)\nx = L.Conv2D(64, (5,5), padding='same')(x)\nx = L.BatchNormalization()(x)\nbranch_2 = L.Activation('relu')(x)\n\n# concatenate + output\nconcat = L.Concatenate()([branch_1, branch_2])\nglobal_pool = L.GlobalAveragePooling2D()(concat)\nfc1 = L.Dense(32, activation='relu')(global_pool)\nfc2 = L.Dense(32, activation='relu')(fc1)\nfc3 = L.Dense(32, activation='relu')(fc2)\nout = L.Dense(9, activation='softmax')(fc3)\n\n# aggregate into model\nmodel = keras.models.Model(inputs=inp, outputs=out)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:20:06.6396Z","iopub.execute_input":"2021-08-26T17:20:06.639929Z","iopub.status.idle":"2021-08-26T17:20:06.645196Z","shell.execute_reply.started":"2021-08-26T17:20:06.639898Z","shell.execute_reply":"2021-08-26T17:20:06.644013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.fit(tf_train_x, y_train, epochs=100, validation_data=(tf_test_x, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:20:06.902514Z","iopub.execute_input":"2021-08-26T17:20:06.902825Z","iopub.status.idle":"2021-08-26T17:20:06.906339Z","shell.execute_reply.started":"2021-08-26T17:20:06.902793Z","shell.execute_reply":"2021-08-26T17:20:06.90549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, show_shapes=True, to_file='arch.png', dpi=400)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:20:07.218908Z","iopub.execute_input":"2021-08-26T17:20:07.219187Z","iopub.status.idle":"2021-08-26T17:20:07.222993Z","shell.execute_reply.started":"2021-08-26T17:20:07.219161Z","shell.execute_reply":"2021-08-26T17:20:07.22176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Negative Learning for Noisy Labels","metadata":{}},{"cell_type":"markdown","source":"Note that for good performance, each stage of training requires training for at least 100 epochs, if not more. If one stage is not sufficiently trained/developed, it creates a performance bottleneck and stunts the performance of following stages and the pipeline as a whole.","metadata":{}},{"cell_type":"markdown","source":"### Process Data","metadata":{}},{"cell_type":"markdown","source":"Loading CIFAR-10 dataset from Keras datasets.","metadata":{}},{"cell_type":"code","source":"# load data\n(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n\n# generate corrupted datasets for corruption\ncy_train = np.copy(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:48:10.413856Z","iopub.execute_input":"2021-08-26T17:48:10.414181Z","iopub.status.idle":"2021-08-26T17:48:11.15457Z","shell.execute_reply.started":"2021-08-26T17:48:10.414151Z","shell.execute_reply":"2021-08-26T17:48:11.153715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adding noise by randomly corrupting 30% of the labels.","metadata":{}},{"cell_type":"code","source":"# define percent\nperc = 0.2\n\n# randomly select [perc*100]% elements from list of indices w/out replacement and sort\nselected_indices = np.sort(np.random.choice(np.arange(len(x_train)),\n                                            int(round(perc*len(x_train))),\n                                            replace=False))\n\n# define list to store corrupted labels\nnew_values = []\n\n# loop through selected indices\nfor ind in tqdm(selected_indices):\n    \n    # get true label\n    true_label = y_train[ind][0]\n    \n    # select random corrupted label\n    corrupted = np.random.choice([i for i in range(10) if i!=true_label])\n    \n    # append to new values\n    new_values.append(corrupted)\n\n# assign corrupted labels    \ncy_train[selected_indices] = np.array(new_values).reshape((len(new_values),1))","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:48:12.579429Z","iopub.execute_input":"2021-08-26T17:48:12.579784Z","iopub.status.idle":"2021-08-26T17:48:13.133696Z","shell.execute_reply.started":"2021-08-26T17:48:12.579752Z","shell.execute_reply":"2021-08-26T17:48:13.132616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate negative labels.","metadata":{}},{"cell_type":"code","source":"# generate negative learning labels\nny_train = np.copy(cy_train)\n\n# loop through training data\nfor ind in tqdm(range(len(ny_train))):\n    listed_label = cy_train[ind][0]\n    negative_label = np.random.choice([i for i in range(10) if i!=listed_label])\n    ny_train[ind] = negative_label","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:49:44.62027Z","iopub.execute_input":"2021-08-26T17:49:44.620599Z","iopub.status.idle":"2021-08-26T17:49:46.650704Z","shell.execute_reply.started":"2021-08-26T17:49:44.620553Z","shell.execute_reply":"2021-08-26T17:49:46.649724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initially train standard model via negative learning.","metadata":{}},{"cell_type":"code","source":"# special loss function\nimport keras.backend as K\ndef special_loss(y_true, y_pred):\n    y_true, y_pred = tf.cast(y_true, tf.float32), tf.cast(y_pred, tf.float32)\n    log_inp = tf.clip_by_value(1-y_pred, 1e-5, 1.-1e-5)\n    return -tf.reduce_mean(y_true * K.log(log_inp), axis=-1)\n\n# create and train model\nfrom tensorflow.python.keras.applications.efficientnet import EfficientNetB3\ninp = L.Input((32,32,3))\nbase_model = EfficientNetB3(\n    include_top=True, weights=None, input_tensor=inp, classes=10\n)\nnl_model = keras.models.Model(inputs=inp,\n                              outputs=base_model.output)\nsgd = keras.optimizers.SGD(learning_rate=0.025, momentum=0.1, nesterov=True)\nnl_model.compile(optimizer=sgd,\n                 loss=special_loss)\nnl_model.fit(x_train, keras.utils.to_categorical(ny_train),\n             epochs=100)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:59:43.510599Z","iopub.execute_input":"2021-08-26T17:59:43.510959Z","iopub.status.idle":"2021-08-26T18:03:53.845023Z","shell.execute_reply.started":"2021-08-26T17:59:43.510922Z","shell.execute_reply":"2021-08-26T18:03:53.842674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Selective negative learning - filter out problematic data.","metadata":{}},{"cell_type":"code","source":"# get predictions\npredictions = nl_model.predict(x_train)\n\n# get mask to select data w/ prediction confidence for positive label > 1/10\nmask = [True if predictions[ind][cy_train[ind][0]] > 1/10 else False for ind in tqdm(range(len(x_train)))]\n\n# select data for mask\nselnl_x_train = x_train[mask]\nselnl_y_train = ny_train[mask]\n\n# continue to fit model\nnl_model.fit(selnl_x_train, selnl_y_train,\n             epochs=100)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T18:05:22.706621Z","iopub.execute_input":"2021-08-26T18:05:22.706948Z","iopub.status.idle":"2021-08-26T18:20:08.329085Z","shell.execute_reply.started":"2021-08-26T18:05:22.70692Z","shell.execute_reply":"2021-08-26T18:20:08.326754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Selective positive learning - filter out problematic data and train SelPL model on filtered data","metadata":{}},{"cell_type":"code","source":"# get predictions\npredictions = nl_model.predict(x_train)\n\n# get mask to select data w/ prediction confidence for positive label > 0.4\nmask = [True if predictions[ind][ny_train[ind][0]] > 0.4 else False for ind in tqdm(range(len(x_train)))]\n\n# select data for mask\nselpl_x_train = x_train[mask]\nselpl_y_train = cy_train[mask]\n\n# recompile with new loss\nnl_model.compile(optimizer='adam',\n                 loss='sparse_categorical_crossentropy')\n\n# continue to fit model\nnl_model.fit(selpl_x_train, selpl_y_train,\n             epochs=100)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T18:20:42.015952Z","iopub.execute_input":"2021-08-26T18:20:42.016269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Separate into corrupted and noncorrupted datasets.","metadata":{}},{"cell_type":"code","source":"# get predictions\npredictions = nl_model.predict(x_train)\n\n# get mask to separate into corrupted & noncorrupted\nmask = [True if predictions[ind][cy_train[ind][0]] > 0.5 else False for ind in tqdm(range(len(x_train)))]\n\n# select data for mask\nclean_x_train = x_train[mask]\nclean_y_train = cy_train[mask]\nunclean_x_train = x_train[[not boolean for boolean in mask]]\n\n# fit model on clean dataset\ninp = L.Input((32,32,3))\nbase_model = EfficientNetB3(\n    include_top=True, weights=None, input_tensor=inp, classes=10\n)\nmodel = keras.models.Model(inputs=inp,\n                           outputs=base_model.output)\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n               metrics=['accuracy'])\nmodel.fit(clean_x_train, clean_y_train,\n          epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:49:25.986525Z","iopub.execute_input":"2021-08-26T02:49:25.986898Z","iopub.status.idle":"2021-08-26T02:51:33.348714Z","shell.execute_reply.started":"2021-08-26T02:49:25.986864Z","shell.execute_reply":"2021-08-26T02:51:33.346015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get predictions of cleaned model on unclean dataset + correct corrupted labels.","metadata":{}},{"cell_type":"code","source":"pred_labels = model.predict(unclean_x_train)\nunclean_y_train = []\nfor ind in tqdm(range(len(unclean_x_train))):\n    label = np.where(pred_labels[ind]==np.max(pred_labels[ind]))\n    unclean_y_train.append(label)\nunclean_y_train = np.array(unclean_y_train).reshape((len(unclean_y_train),1))","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:51:37.928177Z","iopub.execute_input":"2021-08-26T02:51:37.92851Z","iopub.status.idle":"2021-08-26T02:51:57.935638Z","shell.execute_reply.started":"2021-08-26T02:51:37.92848Z","shell.execute_reply":"2021-08-26T02:51:57.934768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create final cleaned dataset and train new model on clean dataset.","metadata":{}},{"cell_type":"code","source":"# concatenate datasets (unclean datasets have been cleaned)\nfinal_clean_x_train = np.concatenate([clean_x_train, unclean_x_train])\nfinal_clean_y_train = np.concatenate([clean_y_train, unclean_y_train])\n\n# fit model on complete final dataset\ninp = L.Input((32,32,3))\nxception = EfficientNetB3(\n    include_top=True, weights=None, input_tensor=inp, classes=10\n)\nmodel = keras.models.Model(inputs=inp,\n                           outputs=xception.output)\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n               metrics=['accuracy'])\nmodel.fit(final_clean_x_train, final_clean_y_train,\n          epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:52:00.293929Z","iopub.execute_input":"2021-08-26T02:52:00.294257Z","iopub.status.idle":"2021-08-26T02:55:17.247218Z","shell.execute_reply.started":"2021-08-26T02:52:00.294228Z","shell.execute_reply":"2021-08-26T02:55:17.243652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compare this performance to a model trained on the original corrupted dataset.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Siamese Networks","metadata":{}},{"cell_type":"markdown","source":"### Setting Up Data Pairs","metadata":{}},{"cell_type":"code","source":"# configurations\nclass_size = 10\n\n# load MNIST data\n(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n\n# select x instances from each class\nsamp_x_train, samp_y_train = [], []\nfor digit in range(10):\n    indices = (y_train == digit).nonzero()[0]\n    selected = np.random.choice(indices, size=class_size)\n    samp_x_train.append(X_train[selected])\n    samp_y_train.append(y_train[selected])\n\n# convert data\nsamp_x_train = np.array(samp_x_train)/255\nsamp_x_train = samp_x_train.reshape((10*class_size, 28, 28, 1))\nsamp_y_train = np.array(samp_y_train)/255\nsamp_y_train = samp_y_train.reshape((10*class_size, 1))\n\n# generate pairs\nfs_x_train_1, fs_x_train_2, fs_y_train = [], [], []\nindices = list(range(10*class_size))\nfor ind_1 in indices:\n    label1 = samp_y_train[ind_1]\n    for ind_2 in indices[ind_1:]:\n        label2 = samp_y_train[ind_2]\n        \n        # append x\n        fs_x_train_1.append(samp_x_train[ind_1])\n        fs_x_train_2.append(samp_x_train[ind_2])\n        \n        # append similarity label\n        if label1 == label2:\n            fs_y_train.append(1)\n        else:\n            fs_y_train.append(0)\nfs_x_train_1 = np.array(fs_x_train_1)\nfs_x_train_2 = np.array(fs_x_train_2)\nfs_y_train = np.array(fs_y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T23:12:43.490032Z","iopub.status.idle":"2021-08-24T23:12:43.490572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build Siamese Network Architecture","metadata":{}},{"cell_type":"code","source":"from keras import layers\ninp = layers.Input((28, 28, 1))\nx = tf.keras.layers.BatchNormalization()(inp)\nx = layers.Conv2D(4, (5, 5), activation=\"tanh\")(x)\nx = layers.AveragePooling2D(pool_size=(2, 2))(x)\nx = layers.Conv2D(16, (5, 5), activation=\"tanh\")(x)\nx = layers.AveragePooling2D(pool_size=(2, 2))(x)\nx = layers.Flatten()(x)\n\nx = tf.keras.layers.BatchNormalization()(x)\nx = layers.Dense(10, activation=\"tanh\")(x)\nembedding_network = keras.Model(inp, x)\n\n\ninput_1 = layers.Input((28, 28, 1), name='inp1')\ninput_2 = layers.Input((28, 28, 1), name='inp2')\n\ntower_1 = embedding_network(input_1)\ntower_2 = embedding_network(input_2)\n\nmerge_layer = layers.Lambda(distance)([tower_1, tower_2])\nnormal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\noutput_layer = layers.Dense(1, activation=\"sigmoid\")(normal_layer)\nmodel = keras.Model(inputs=[input_1, input_2], outputs=output_layer)\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nmodel.fit({'inp1':fs_x_train_1, 'inp2':fs_x_train_2},\n          fs_y_train,\n          epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T23:12:43.491439Z","iopub.status.idle":"2021-08-24T23:12:43.492035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parallel_branch():\n    inp_layer = L.Input((28,28,1))\n    x = L.BatchNormalization()(inp_layer)\n    x = L.Conv2D(32, (3,3), activation='relu')(x)\n    x = L.Conv2D(32, (3,3), activation='relu')(x)\n    x = L.MaxPooling2D((2,2))(x)\n    x = L.Conv2D(64, (3,3), activation='relu')(x)\n    x = L.Conv2D(64, (3,3), activation='relu')(x)\n    x = L.MaxPooling2D((2,2))(x)\n    x = L.Flatten()(x)\n    x = L.Dense(16, activation='relu')(x)\n    branch = keras.models.Model(inputs=inp_layer,\n                                outputs=x)\n    return branch\n\ndef distance(representations):\n    reps1, reps2 = representations\n    squared = K.sum(K.square(reps1-reps2), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(squared,K.epsilon()))\n\ninp1 = L.Input((28,28,1), name='inp1')\ninp2 = L.Input((28,28,1), name='inp2')\nbranch = parallel_branch()\nreps1 = branch(inp1)\nreps2 = branch(inp2)\ndist = L.Lambda(distance)([reps1, reps2])\nout = L.Dense(1, activation='sigmoid')(dist)\nmodel = keras.models.Model(inputs={'inp1':inp1, 'inp2':inp2},\n                           outputs=out)\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nmodel.fit({'inp1':fs_x_train_1, 'inp2':fs_x_train_2},\n          fs_y_train,\n          epochs=100)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T23:12:43.492959Z","iopub.status.idle":"2021-08-24T23:12:43.493492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}}]}